{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"K-means/main/","title":"K-means","text":""},{"location":"K-means/main/#exploracao","title":"explora\u00e7\u00e3o","text":"<p>O dataset cont\u00e9m 4601 observa\u00e7\u00f5es, no qual cada linha representa um email, descrito por 58 atributos. Desses, 57 s\u00e3o caracter\u00edsticas extra\u00eddas do texto (frequ\u00eancia de palavras, caracteres especiais, uso de mai\u00fasculas, etc.) e 1 \u00e9 a vari\u00e1vel alvo (is_spam), indicando se o email \u00e9 spam (1) ou n\u00e3o-spam (0).</p> <p>Como o K-Means \u00e9 um m\u00e9todo n\u00e3o supervisionado, nesta se\u00e7\u00e3o usamos somente as features (sem o alvo) para explorar a separabilidade natural dos dados. Ou seja para aplicar o algoritmo de agrupamento K-Means, n\u00e3o utilizamos o alvo (is_spam), pois o objetivo \u00e9 agrupar automaticamente os dados em clusters com base em suas caracter\u00edsticas.</p> <p>Escolha do n\u00famero de clusters (k)</p> <p>M\u00e9todo do elbow (WCSS)</p>"},{"location":"K-means/main/#definicao-do-numero-de-clusters","title":"Defini\u00e7\u00e3o do N\u00famero de Clusters","text":"<p>Uma etapa cr\u00edtica no K-Means \u00e9 escolher o valor de k (n\u00famero de clusters). Para isso, avaliamos:</p> <p>M\u00e9todo elbow(WCSS)</p> <p></p> <p>O gr\u00e1fico de in\u00e9rcia (WCSS) em fun\u00e7\u00e3o de k ajuda a identificar um ponto de \u201ccotovelo\u201d, onde a redu\u00e7\u00e3o de WCSS passa a ser marginal. Para este conjunto, k = 2 \u00e9 um candidato natural (compat\u00edvel com spam vs. n\u00e3o-spam), embora valores maiores tamb\u00e9m possam capturar subgrupos com padr\u00f5es semelhantes.</p> <p>Coeficiente de Silhouette</p> <p></p> <p>O coeficiente de Silhouette mede, de \u22121 a 1, o qu\u00e3o coesos e separados est\u00e3o os clusters. Valores mais altos indicam melhor separa\u00e7\u00e3o intr\u00ednseca. Usamos este gr\u00e1fico para confirmar a escolha de k observada no cotovelo.</p> <p>visto isso, utilizamos os seguinte clusters:</p> <p>char_freq_! (uso do caractere \"!\")</p> <p>word_freq_free (uso da palavra \"free\")</p> <p>O gr\u00e1fico abaixo mostra os dois clusters encontrados pelo K-Means, com seus respectivos centr\u00f3ides (estrelas vermelhas):</p> <p></p> <p>Emails com maior frequ\u00eancia de \"!\" e \"free\" tendem a ser agrupados no cluster associado a spam. J\u00e1 Emails com baixa frequ\u00eancia desses elementos ficam concentrados no cluster de n\u00e3o-spam.</p>"},{"location":"K-means/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de K-Means aplicado ao dataset Spambase mostrou-se uma ferramenta \u00fatil para a explora\u00e7\u00e3o e identifica\u00e7\u00e3o de padr\u00f5es nos emails. As features, ou seja, as vari\u00e1veis que descrevem cada mensagem, como a frequ\u00eancia da palavra \u201cfree\u201d e o uso do caractere \u201c!\u201d, tiveram papel fundamental na forma\u00e7\u00e3o dos clusters, os grupos criados automaticamente pelo algoritmo. Observou-se que os emails com maior presen\u00e7a desses elementos tendem a ser agrupados em um cluster associado ao spam, enquanto aqueles com baixa frequ\u00eancia permanecem no grupo de n\u00e3o-spam. Embora o K-Means n\u00e3o atinja o mesmo desempenho de modelos supervisionados, como a \u00c1rvore de Decis\u00e3o ou o KNN, ele alcan\u00e7ou uma separa\u00e7\u00e3o satisfat\u00f3ria das classes, evidenciando que as caracter\u00edsticas lingu\u00edsticas e de formata\u00e7\u00e3o s\u00e3o fortes indicadores de spam. Essa abordagem refor\u00e7a o valor do K-Means como t\u00e9cnica explorat\u00f3ria, capaz de revelar padr\u00f5es ocultos nos dados e oferecer uma vis\u00e3o inicial relevante, mesmo sem utilizar a vari\u00e1vel alvo.</p>"},{"location":"KNN/main/","title":"Knn","text":""},{"location":"KNN/main/#exploracao","title":"explora\u00e7\u00e3o","text":"<p>O dataset cont\u00e9m 4601 observa\u00e7\u00f5es, no qual cada linha representa um email, descrito por 58 atributos. Desses, 57 s\u00e3o caracter\u00edsticas extra\u00eddas do texto (frequ\u00eancia de palavras, caracteres especiais, uso de mai\u00fasculas, etc.) e 1 \u00e9 a vari\u00e1vel alvo (is_spam), indicando se o email \u00e9 spam (1) ou n\u00e3o-spam (0).</p> <p>Assim como na etapa da \u00e1rvore de decis\u00e3o, foi realizada uma an\u00e1lise explorat\u00f3ria para compreender melhor o comportamento das classes e identificar os atributos mais relevantes.</p>"},{"location":"KNN/main/#dispersao-por-classe","title":"Dispers\u00e3o por classe","text":"<p>O gr\u00e1fico de dispers\u00e3o foi constru\u00eddo utilizando a frequ\u00eancia do caractere ! e a palavra \u201cfree\u201d, ambos comuns em spams. Percebe-se que os emails classificados como spam (X vermelho) tendem a concentrar maiores valores dessas vari\u00e1veis, enquanto os n\u00e3o-spam (c\u00edrculos azuis) aparecem em menor intensidade.</p> <p></p> <p>Dos 921 emails no conjunto de teste, 836 foram classificados corretamente.</p> <p>A classe N\u00e3o-Spam obteve precis\u00e3o de 92% e recall de 93%.</p> <p>A classe Spam apresentou precis\u00e3o de 89% e recall de 88%, ou seja, teve um pouco mais de dificuldade em identificar spams corretamente, mas ainda com bom desempenho.</p> <p>Esses n\u00fameros indicam que o modelo tem boa capacidade de generaliza\u00e7\u00e3o, conseguindo capturar padr\u00f5es importantes para distinguir spam de n\u00e3o-spam.</p> <p></p> <p>Foi avaliado o impacto da escolha de k no desempenho. Valores muito pequenos de k tendem a causar overfitting (alta variabilidade), enquanto valores muito grandes podem suavizar demais as fronteiras de decis\u00e3o.</p> <p>O melhor equil\u00edbrio foi observado em torno de k=5, valor adotado para os testes principais.</p> <p></p> <p>Esse gr\u00e1fico mostra a proje\u00e7\u00e3o dos dados em duas dimens\u00f5es (PCA 1 e PCA 2) para permitir a visualiza\u00e7\u00e3o da fronteira de decis\u00e3o do KNN. As regi\u00f5es coloridas de fundo indicam onde o modelo classifica como spam ou n\u00e3o-spam, enquanto os pontos representam os exemplos reais do conjunto de treino (roxos) e de teste (amarelos). Observa-se que a maior concentra\u00e7\u00e3o dos pontos est\u00e1 pr\u00f3xima ao centro, regi\u00e3o em que ocorre maior sobreposi\u00e7\u00e3o entre as classes, o que explica parte dos erros de classifica\u00e7\u00e3o. Ainda assim, \u00e9 poss\u00edvel perceber \u00e1reas bem delimitadas, mostrando que o modelo consegue capturar padr\u00f5es \u00fateis mesmo em um espa\u00e7o reduzido para duas dimens\u00f5es. Essa visualiza\u00e7\u00e3o ilustra como o KNN define suas fronteiras a partir da proximidade entre os pontos, destacando tanto a efic\u00e1cia quanto as limita\u00e7\u00f5es do m\u00e9todo em cen\u00e1rios com dados parcialmente sobrepostos.</p>"},{"location":"KNN/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de KNN aplicado ao dataset Spambase apresentou um desempenho consistente, alcan\u00e7ando cerca de 91% de acur\u00e1cia nos dados de teste. Esse resultado demonstra que o algoritmo foi capaz de aprender padr\u00f5es relevantes que diferenciam mensagens leg\u00edtimas de spams, oferecendo uma solu\u00e7\u00e3o simples, por\u00e9m eficiente, para esse tipo de tarefa.</p> <p>Diferentemente da \u00c1rvore de Decis\u00e3o, que gera regras interpret\u00e1veis e permite visualizar a import\u00e2ncia de cada vari\u00e1vel, o KNN se apoia unicamente na proximidade entre exemplos no espa\u00e7o de atributos. Essa caracter\u00edstica faz com que o modelo seja menos transparente em termos de explica\u00e7\u00e3o, mas ao mesmo tempo garante flexibilidade, j\u00e1 que ele pode se adaptar bem a fronteiras de decis\u00e3o complexas.</p> <p>A an\u00e1lise explorat\u00f3ria refor\u00e7ou que atributos como a presen\u00e7a da palavra \u201cfree\u201d, o uso de caracteres especiais como \u201c!\u201d e \u201c$\u201d, al\u00e9m da frequ\u00eancia de letras mai\u00fasculas, est\u00e3o fortemente associados ao spam. Esses sinais refletem pr\u00e1ticas comuns em mensagens indesejadas, como apelos visuais e tentativas de chamar a aten\u00e7\u00e3o do usu\u00e1rio.</p> <p>Apesar da boa performance, algumas limita\u00e7\u00f5es s\u00e3o inerentes ao KNN. O algoritmo demanda maior custo computacional em bases grandes, pois cada nova predi\u00e7\u00e3o exige o c\u00e1lculo da dist\u00e2ncia em rela\u00e7\u00e3o a todos os pontos de treinamento. Al\u00e9m disso, seu desempenho \u00e9 sens\u00edvel \u00e0 escolha do par\u00e2metro k e \u00e0 necessidade de normaliza\u00e7\u00e3o dos dados \u2014 aspectos que, se n\u00e3o tratados corretamente, podem reduzir sua efic\u00e1cia.</p> <p>De forma geral, o KNN mostrou-se uma alternativa vi\u00e1vel e robusta para a classifica\u00e7\u00e3o de spams no dataset Spambase, com a vantagem de ser um m\u00e9todo intuitivo e de f\u00e1cil implementa\u00e7\u00e3o. No entanto, para cen\u00e1rios de produ\u00e7\u00e3o em larga escala, seria interessante compar\u00e1-lo com algoritmos mais escal\u00e1veis e interpret\u00e1veis, de modo a equilibrar desempenho, custo e explicabilidade.</p>"},{"location":"Page_rank/main/","title":"Page_Rank","text":""},{"location":"Page_rank/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>Para este projeto foi utilizado o dataset Email-Eu-core, uma rede de comunica\u00e7\u00f5es internas de uma institui\u00e7\u00e3o europeia.</p> <p>O dataset cont\u00e9m:</p> <p>1005 n\u00f3s, representando funcion\u00e1rios</p> <p>25.571 arestas direcionadas, representando e-mails enviados de um funcion\u00e1rio para outro</p> <p>Formato original: Matrix Market (.mtx)</p> <p>Esse tipo de rede \u00e9 \u00fatil para entender como a informa\u00e7\u00e3o circula em organiza\u00e7\u00f5es, identificar hubs de comunica\u00e7\u00e3o e analisar padr\u00f5es de conectividade.</p> <p>Para compreender melhor os dados antes da aplica\u00e7\u00e3o do PageRank, o grafo foi carregado, analisado e preparado para o algoritmo.</p>"},{"location":"Page_rank/main/#estrutura-do-grafo","title":"Estrutura do Grafo","text":"<p>O grafo \u00e9 dirigido, pois cada aresta representa:</p> <p>funcion\u00e1rio A \u2192 funcion\u00e1rio B (A enviou e-mail para B)</p> <p>A rede apresenta conectividade densa, com v\u00e1rios funcion\u00e1rios trocando mensagens entre si.</p>"},{"location":"Page_rank/main/#implementacao-do-pagerank","title":"Implementa\u00e7\u00e3o do PageRank","text":"<p>O objetivo da atividade foi implementar o PageRank do zero, utilizando a f\u00f3rmula iterativa tradicional:</p> <p></p> <pre><code>\u200b\n</code></pre> <p>Onde:</p> <p>d = damping factor</p> <p>N = total de n\u00f3s</p> <p>In(i) = n\u00f3s que apontam para i</p> <p>L _ j = n\u00famero de sa\u00eddas de j</p> <p>dangling mass = n\u00f3s sem arestas de sa\u00edda</p> <p>Foram testados tr\u00eas valores de d:</p> <p>0.5</p> <p>0.85 (valor cl\u00e1ssico do algoritmo)</p> <p>0.99</p> <p>O PageRank manual foi comparado com o networkx.pagerank como refer\u00eancia.</p>"},{"location":"Page_rank/main/#convergencia-e-validacao","title":"Converg\u00eancia e Valida\u00e7\u00e3o","text":"<p>A converg\u00eancia ocorreu com sucesso em todos os testes:</p> <p></p> <p>Essas diferen\u00e7as s\u00e3o extremamente pequenas, confirmando:</p> <ul> <li> <p>a corre\u00e7\u00e3o da implementa\u00e7\u00e3o manual.</p> </li> <li> <p>a estabilidade do m\u00e9todo iterativo.</p> </li> <li> <p>e o comportamento esperado conforme o valor de d aumenta (mais itera\u00e7\u00f5es).</p> </li> </ul>"},{"location":"Page_rank/main/#top-10-nos-mais-importantes-por-pagerank","title":"Top 10 N\u00f3s Mais Importantes por PageRank","text":"<p>A seguir est\u00e3o os n\u00f3s com maior PageRank para cada valor de d.</p>"},{"location":"Page_rank/main/#d-05-distribuicao-mais-homogenea","title":"d = 0.5 \u2014 Distribui\u00e7\u00e3o mais homog\u00eanea","text":"<p>O algoritmo se comporta de forma mais aleat\u00f3ria, reduzindo a influ\u00eancia da estrutura da rede.</p> <p></p> <p>Interpreta\u00e7\u00e3o:</p> <p>A import\u00e2ncia fica mais distribu\u00edda. N\u00e3o h\u00e1 super-hubs evidentes.</p>"},{"location":"Page_rank/main/#d-085-cenario-padrao-do-pagerank","title":"d = 0.85 \u2014 Cen\u00e1rio padr\u00e3o do PageRank","text":"<p>Este valor \u00e9 considerado o mais equilibrado entre navega\u00e7\u00e3o aleat\u00f3ria e estrutura da rede.</p> <p></p> <p>Interpreta\u00e7\u00e3o:</p> <p>O n\u00f3 2 se destaca como o maior hub da organiza\u00e7\u00e3o, seguido por 131 e 161.</p> <p>Esses indiv\u00edduos provavelmente representam funcion\u00e1rios altamente centrais no fluxo de comunica\u00e7\u00e3o interno.</p>"},{"location":"Page_rank/main/#d-099-forte-dependencia-da-estrutura","title":"d = 0.99 \u2014 Forte depend\u00eancia da estrutura","text":"<p>Aqui o teleporte quase n\u00e3o ocorre, e o PageRank concentra a import\u00e2ncia nos hubs.</p> <p></p> <p>Interpreta\u00e7\u00e3o:</p> <p>Os valores explodem, mostrando forte centraliza\u00e7\u00e3o.</p> <p>O n\u00f3 2 passa de 0.009 \u2192 0.093, quase 10\u00d7 mais influ\u00eancia.</p> <p>Isso revela que a rede tem poucos hubs muito conectados que dominam a comunica\u00e7\u00e3o.</p> <p>An\u00e1lise do Impacto do Damping Factor</p> <p></p>"},{"location":"Page_rank/main/#conclusao","title":"Conclus\u00e3o:","text":"<p>d baixo \u2192 o algoritmo se torna mais democr\u00e1tico</p> <p>d padr\u00e3o \u2192 ressaltam os funcion\u00e1rios realmente importantes</p> <p>d alto \u2192 supervaloriza hubs e aumenta desigualdade no ranking</p>"},{"location":"Page_rank/main/#logo","title":"Logo:","text":"<p>O PageRank aplicado ao dataset email-Eu-core permitiu identificar:</p> <p>Funcion\u00e1rios centrais no fluxo de comunica\u00e7\u00e3o.</p> <p>Padr\u00f5es de hierarquia informal.</p> <p>A import\u00e2ncia da estrutura da rede na determina\u00e7\u00e3o da influ\u00eancia.</p> <p>A implementa\u00e7\u00e3o manual demonstrou alta fidelidade ao algoritmo original, com baix\u00edssima diferen\u00e7a em rela\u00e7\u00e3o ao NetworkX.</p> <p>O valor d = 0.85 produziu o ranking mais interpret\u00e1vel, enquanto valores extremos de d mostram como o comportamento do \u201cnavegador aleat\u00f3rio\u201d influencia o n\u00edvel de concentra\u00e7\u00e3o da import\u00e2ncia.</p> <p>Este estudo confirma que o PageRank \u00e9 uma ferramenta eficaz para an\u00e1lise de redes sociais internas e pode ser usado para identificar hubs de informa\u00e7\u00e3o, gargalos comunicacionais e potenciais l\u00edderes informais dentro de organiza\u00e7\u00f5es.</p>"},{"location":"Random-Forest/main/","title":"Modelo de Random Forest","text":""},{"location":"Random-Forest/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Ap\u00f3s a implementa\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o, o pr\u00f3ximo passo foi aplicar o Random Forest, uma t\u00e9cnica de aprendizado supervisionado baseada no princ\u00edpio do ensemble learning. O m\u00e9todo consiste em treinar diversas \u00e1rvores de decis\u00e3o independentes e combinar seus resultados, de modo que o voto majorit\u00e1rio determine a classifica\u00e7\u00e3o final.</p> <p>Essa abordagem reduz o risco de overfitting (quando o modelo \u201cdecorra\u201d os dados de treino) e aumenta a precis\u00e3o geral da previs\u00e3o, tornando o modelo mais robusto e est\u00e1vel.</p>"},{"location":"Random-Forest/main/#implementacao-do-modelo","title":"Implementa\u00e7\u00e3o do Modelo","text":"<p>O modelo foi implementado utilizando apenas a biblioteca scikit-learn, conforme a metodologia adotada em aula.</p> <p>from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import pandas as pd from pathlib import Path import numpy as np</p> <p>--&gt; Carrega o dataset Spambase</p> <p>PATH_DATA = Path(\"source\") df = pd.read_csv(PATH_DATA / \"spambase.csv\", header=None, names=colnames)</p> <p>X = df.drop(columns=[\"is_spam\"]) y = df[\"is_spam\"].astype(int)</p> <p>--&gt; Divide os dados em treino e teste (80/20)</p> <p>X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.2, random_state=42 )</p> <p>--&gt; Cria e treina o modelo Random Forest</p> <p>rf = RandomForestClassifier(     n_estimators=100,     max_depth=5,     max_features='sqrt',     random_state=42 ) rf.fit(X_train, y_train)</p> <p>--&gt; Avalia o modelo</p> <p>pred = rf.predict(X_test) print(f\"Accuracy: {accuracy_score(y_test, pred):.4f}\")</p> <p>--&gt; Mostra as 10 features mais importantes</p> <p>importances = rf.feature_importances_ feat_names = np.array(X.columns) order = np.argsort(importances)[::-1][:10]</p>"},{"location":"Random-Forest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O modelo de Random Forest apresentou um excelente desempenho, alcan\u00e7ando uma acur\u00e1cia de 92,4% nos dados de teste. Esse valor indica que, a cada 100 e-mails analisados, aproximadamente 92 foram classificados corretamente como spam ou n\u00e3o-spam.</p> <p>O resultado demonstra que a combina\u00e7\u00e3o de v\u00e1rias \u00e1rvores aumenta significativamente a capacidade de generaliza\u00e7\u00e3o do modelo, tornando-o mais confi\u00e1vel do que uma \u00fanica \u00e1rvore de decis\u00e3o.</p> <p>Principais Vari\u00e1veis (Import\u00e2ncia das Features)</p> <p>As dez vari\u00e1veis mais relevantes identificadas pelo modelo foram:</p> <p>Ranking Feature Import\u00e2ncia 1   char_freq_$ 0.1329 2   char_freq_! 0.1249 3   word_freq_remove    0.1024 4   word_freq_free  0.0787 5   word_freq_hp    0.0551 6   capital_run_length_average  0.0535 7   word_freq_your  0.0522 8   capital_run_length_longest  0.0505 9   capital_run_length_total    0.0424 10  word_freq_money 0.0366</p> <p>Essas vari\u00e1veis refletem com clareza o comportamento t\u00edpico de e-mails de spam:</p> <p>S\u00edmbolos monet\u00e1rios e de \u00eanfase ($ e !) aparecem em excesso, buscando chamar a aten\u00e7\u00e3o do leitor.</p> <p>Palavras-chave como \u201cfree\u201d, \u201cmoney\u201d e \u201cyour\u201d s\u00e3o amplamente utilizadas para promover ofertas enganosas.</p> <p>Letras mai\u00fasculas e longos blocos de texto em caixa alta (capital_run_length) refor\u00e7am o padr\u00e3o apelativo caracter\u00edstico de mensagens de spam.</p>"},{"location":"Random-Forest/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de Random Forest aplicado ao dataset Spambase apresentou \u00f3tima performance e forte capacidade de generaliza\u00e7\u00e3o, com acur\u00e1cia de 92,4%. A t\u00e9cnica demonstrou-se mais est\u00e1vel e precisa que uma \u00e1rvore de decis\u00e3o isolada, pois reduz o impacto de ru\u00eddos e outliers no conjunto de dados.</p> <p>A an\u00e1lise das vari\u00e1veis mais importantes confirma o comportamento esperado: spams utilizam linguagem apelativa, repetem s\u00edmbolos de \u00eanfase e abusam de termos relacionados a ganhos financeiros.</p> <p>De forma geral, o Random Forest mostrou-se uma ferramenta eficiente e confi\u00e1vel para detec\u00e7\u00e3o autom\u00e1tica de e-mails spam \u2014 equilibrando desempenho, interpretabilidade e robustez.</p>"},{"location":"arvore-decisao/main/","title":"\u00c1rvore de Decis\u00e3o","text":""},{"location":"arvore-decisao/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>Para o projeto foi utilizado o dataset Spambase</p> <p>O dataset utilizado foi o Spambase, Ele cont\u00e9m 4601 observa\u00e7\u00f5es, no qual s\u00e3o emails e apresenta 58 atributos, sendo 57 caracter\u00edsticas para avaliar se o email \u00e9 spam ou n\u00e3o e 1 alvo indicando spam ou n\u00e3o-spam. </p> <p>Para entendermos melhor os dados que estamos manipulando, foi gerado algumas analises baseado nos dados do projeto.</p>"},{"location":"arvore-decisao/main/#distribuicao-da-classe","title":"Distribui\u00e7\u00e3o da Classe","text":"<p>O dataset cont\u00e9m 4601, 2788 emails n\u00e3o-spam e 1813 emails spam. Apesar de n\u00e3o ser perfeitamente balanceado, ainda h\u00e1 uma boa representatividade das duas classes.</p>"},{"location":"arvore-decisao/main/#top-10-palavras-mais-frequentes","title":"Top 10 Palavras mais Frequentes","text":"<p>As palavras mais comuns em emails incluem \u201cyou\u201d, \u201cyour\u201d, \u201cfree\u201d e \u201cour\u201d. Palavras utilizadas com frequencia pelas pessoas e que mostra como spams apelam para comunica\u00e7\u00e3o direta com o usu\u00e1rio e ofertas atrativas.</p> <p>Observa\u00e7\u00e3o: george\", \"hp\", \"hpl\" aparecem bastante porque o dataset Spambase foi coletado a partir de emails internos da Hewlett-Packard (HP) nos anos 90. Ou seja, s\u00e3o termos de contexto espec\u00edfico.</p>"},{"location":"arvore-decisao/main/#caracteres-especiais-por-classe","title":"Caracteres Especiais por Classe","text":"<p>Emails classificados como spam apresentam maior frequ\u00eancia dos caracteres \u201c!\u201d e \u201c$\u201d, usados para chamar aten\u00e7\u00e3o (\u201cOFERTA!!!\u201d, \u201cGANHE $$$\u201d). J\u00e1 os n\u00e3o-spam possuem esses s\u00edmbolos em quantidade bem menor.</p>"},{"location":"arvore-decisao/main/#uso-de-maiusculas","title":"Uso de Mai\u00fasculas","text":"<p>Os spams tendem a utilizar mais letras mai\u00fasculas ao longo do texto, com picos muito acima dos emails normais. Isso reflete a pr\u00e1tica de destacar trechos inteiros com mai\u00fasculas para atrair a aten\u00e7\u00e3o do leitor.</p>"},{"location":"arvore-decisao/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Antes de treinar o modelo, foi realizada uma etapa de pr\u00e9-processamento dos dados. Essa fase \u00e9 fundamental para garantir a qualidade do aprendizado, evitando que inconsist\u00eancias ou ru\u00eddos prejudiquem o desempenho do classificador.</p> <p>Verifica\u00e7\u00e3o de valores nulos Foi utilizado o script exploracao.py para inspecionar o dataset. O teste confirmou que n\u00e3o h\u00e1 valores nulos ou ausentes em nenhuma das 58 colunas, eliminando a necessidade de imputa\u00e7\u00e3o ou exclus\u00e3o de registros.</p> <p>Normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o N\u00e3o foi necess\u00e1rio aplicar normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o das vari\u00e1veis, pois o algoritmo de \u00c1rvore de Decis\u00e3o n\u00e3o depende de escalonamento. Ele realiza divis\u00f5es baseadas em valores de corte (thresholds), o que dispensa ajustes na escala das features.</p> <p>Defini\u00e7\u00e3o das features e do alvo As 57 primeiras colunas foram consideradas como vari\u00e1veis independentes (frequ\u00eancia de palavras, caracteres especiais, uso de mai\u00fasculas, etc.), enquanto a \u00faltima coluna (is_spam) foi definida como vari\u00e1vel alvo, indicando se o email \u00e9 spam (1) ou n\u00e3o-spam (0).</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\nPATH_DATA = Path(\"source\")\nPATH_OUT  = Path(\".\")\nPATH_OUT.mkdir(parents=True, exist_ok=True)\n\n# Tive que fazer isso, porque o arquivo para ler as colunas n\u00e3o estava lendo 58 e apenas 52.\ncolnames = [\n    \"word_freq_make\",\"word_freq_address\",\"word_freq_all\",\"word_freq_3d\",\"word_freq_our\",\n    \"word_freq_over\",\"word_freq_remove\",\"word_freq_internet\",\"word_freq_order\",\"word_freq_mail\",\n    \"word_freq_receive\",\"word_freq_will\",\"word_freq_people\",\"word_freq_report\",\"word_freq_addresses\",\n    \"word_freq_free\",\"word_freq_business\",\"word_freq_email\",\"word_freq_you\",\"word_freq_credit\",\n    \"word_freq_your\",\"word_freq_font\",\"word_freq_000\",\"word_freq_money\",\"word_freq_hp\",\n    \"word_freq_hpl\",\"word_freq_george\",\"word_freq_650\",\"word_freq_lab\",\"word_freq_labs\",\n    \"word_freq_telnet\",\"word_freq_857\",\"word_freq_data\",\"word_freq_415\",\"word_freq_85\",\n    \"word_freq_technology\",\"word_freq_1999\",\"word_freq_parts\",\"word_freq_pm\",\"word_freq_direct\",\n    \"word_freq_cs\",\"word_freq_meeting\",\"word_freq_original\",\"word_freq_project\",\"word_freq_re\",\n    \"word_freq_edu\",\"word_freq_table\",\"word_freq_conference\",\n    \"char_freq_;\",\"char_freq_(\",\"char_freq_[\",\"char_freq_!\",\"char_freq_$\",\"char_freq_#\",\n    \"capital_run_length_average\",\"capital_run_length_longest\",\"capital_run_length_total\",\n    \"is_spam\"\n]\n\n# Ler dados \ndf = pd.read_csv(PATH_DATA / \"spambase.csv\", header=None, names=colnames)\n\n# Separa\u00e7\u00e3o y e X\nX = df.drop(columns=[\"is_spam\"])\ny = df[\"is_spam\"].astype(int)\n\n# Divis\u00e3o treino/teste (80% treino, 20% teste)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinamento do modelo e avalia\u00e7\u00e3o\nclassifier = DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\nprint(f\"Accuracy: {classifier.score(X_test, y_test):.2f}\")\n\n# Visualiza\u00e7\u00e3o da \u00e1rvore de decis\u00e3o\nplt.figure(figsize=(12, 10))\ntree.plot_tree(classifier, max_depth=3, filled=True)\nplt.tight_layout()\nplt.savefig(PATH_OUT / \"tree.png\", dpi=200)\nplt.close()\n</code></pre>"},{"location":"arvore-decisao/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Para avaliar o desempenho do modelo de forma justa, foi necess\u00e1rio dividir o dataset em dois subconjuntos:</p> <p>Treinamento (80%) utilizado para o modelo aprender os padr\u00f5es que diferenciam emails de spam e n\u00e3o-spam. Teste (20%) utilizado apenas ap\u00f3s o treinamento, para verificar a capacidade do modelo de generalizar para dados nunca vistos.</p> <p>A divis\u00e3o foi feita com a fun\u00e7\u00e3o train_test_split da biblioteca scikit-learn, fixando random_state=42 para garantir a reprodutibilidade. Isso significa que, mesmo executando o c\u00f3digo v\u00e1rias vezes, a mesma separa\u00e7\u00e3o entre treino e teste ser\u00e1 obtida.</p> <p>from sklearn.model_selection import train_test_split</p> <p>X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.2, random_state=42 )</p> <p>Esse processo \u00e9 essencial para evitar que o modelo memorize apenas os exemplos dispon\u00edveis (overfitting), garantindo que sua avalia\u00e7\u00e3o reflita sua real capacidade de identificar corretamente novos emails.</p>"},{"location":"arvore-decisao/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>Para a tarefa de classifica\u00e7\u00e3o, foi escolhida a t\u00e9cnica de \u00c1rvore de Decis\u00e3o, implementada atrav\u00e9s da classe DecisionTreeClassifier da biblioteca scikit-learn. Esse algoritmo \u00e9 bastante utilizado em problemas de classifica\u00e7\u00e3o por ser simples, interpret\u00e1vel e permitir visualizar claramente quais vari\u00e1veis tiveram maior import\u00e2ncia na decis\u00e3o final.</p> <p>O modelo foi inicializado com o par\u00e2metro random_state=42, garantindo a reprodutibilidade dos resultados, ou seja, que os mesmos dados de treino e teste levem sempre \u00e0s mesmas divis\u00f5es e ao mesmo desempenho.</p> <p>A etapa de treinamento consistiu em ajustar o modelo (fit) aos dados de treino, fornecendo ao algoritmo 80% das observa\u00e7\u00f5es do dataset. Nesse processo, a \u00e1rvore aprende os padr\u00f5es a partir das vari\u00e1veis independentes e a rela\u00e7\u00e3o delas com a vari\u00e1vel alvo (is_spam).</p> <p>Ao final, a \u00e1rvore de decis\u00e3o foi capaz de gerar uma estrutura hier\u00e1rquica de regras que permitem classificar novos emails como spam ou n\u00e3o-spam.</p>"},{"location":"arvore-decisao/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O modelo atingiu 92% de acur\u00e1cia nos dados de teste.</p> <p>isso quer dizer que, de cada 100 emails, cerca de 92 foram classificados corretamente.</p>"},{"location":"arvore-decisao/main/#conclusao","title":"Conclus\u00e3o","text":""},{"location":"arvore-decisao/main/#visualizacao-da-arvore","title":"Visualiza\u00e7\u00e3o da \u00c1rvore","text":"<p>O modelo de \u00c1rvore de Decis\u00e3o treinado sobre o dataset Spambase apresentou um desempenho consistente, alcan\u00e7ando aproximadamente 92% de acur\u00e1cia nos testes. Esse resultado indica que o algoritmo conseguiu aprender de forma eficaz os padr\u00f5es que diferenciam emails de spam e n\u00e3o-spam.</p> <p>A an\u00e1lise explorat\u00f3ria mostrou que spams costumam utilizar com maior frequ\u00eancia palavras como \u201cyou\u201d e \u201cyour\u201d, empregam intensivamente caracteres especiais como \u201c!\u201d e \u201c$\u201d, e fazem uso exagerado de mai\u00fasculas para chamar a aten\u00e7\u00e3o do leitor. Esses elementos refletem estrat\u00e9gias t\u00edpicas de mensagens indesejadas.</p> <p>Por outro lado, termos como \u201cgeorge\u201d e \u201chp\u201d tamb\u00e9m se destacaram, revelando um vi\u00e9s do dataset, j\u00e1 que ele foi coletado em um contexto corporativo espec\u00edfico (emails da Hewlett-Packard nos anos 90). Isso refor\u00e7a a import\u00e2ncia de avaliar a origem e a atualidade dos dados ao aplicar modelos em cen\u00e1rios reais.</p> <p>De modo geral, a \u00c1rvore de Decis\u00e3o demonstrou ser uma t\u00e9cnica eficaz e interpret\u00e1vel para a tarefa de classifica\u00e7\u00e3o de spam. Mas claro, ainda porderiamos utilizar mais ferramentas para aprimorar a \u00e1rvore.</p>"}]}