{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"K-means/main/","title":"K-means","text":""},{"location":"K-means/main/#exploracao","title":"explora\u00e7\u00e3o","text":"<p>O dataset cont\u00e9m 4601 observa\u00e7\u00f5es, no qual cada linha representa um email, descrito por 58 atributos. Desses, 57 s\u00e3o caracter\u00edsticas extra\u00eddas do texto (frequ\u00eancia de palavras, caracteres especiais, uso de mai\u00fasculas, etc.) e 1 \u00e9 a vari\u00e1vel alvo (is_spam), indicando se o email \u00e9 spam (1) ou n\u00e3o-spam (0).</p> <p>Como o K-Means \u00e9 um m\u00e9todo n\u00e3o supervisionado, nesta se\u00e7\u00e3o usamos somente as features (sem o alvo) para explorar a separabilidade natural dos dados. Ou seja para aplicar o algoritmo de agrupamento K-Means, n\u00e3o utilizamos o alvo (is_spam), pois o objetivo \u00e9 agrupar automaticamente os dados em clusters com base em suas caracter\u00edsticas.</p> <p>Escolha do n\u00famero de clusters (k)</p> <p>M\u00e9todo do elbow (WCSS)</p>"},{"location":"K-means/main/#definicao-do-numero-de-clusters","title":"Defini\u00e7\u00e3o do N\u00famero de Clusters","text":"<p>Uma etapa cr\u00edtica no K-Means \u00e9 escolher o valor de k (n\u00famero de clusters). Para isso, avaliamos:</p> <p>M\u00e9todo elbow(WCSS)</p> <p></p> <p>O gr\u00e1fico de in\u00e9rcia (WCSS) em fun\u00e7\u00e3o de k ajuda a identificar um ponto de \u201ccotovelo\u201d, onde a redu\u00e7\u00e3o de WCSS passa a ser marginal. Para este conjunto, k = 2 \u00e9 um candidato natural (compat\u00edvel com spam vs. n\u00e3o-spam), embora valores maiores tamb\u00e9m possam capturar subgrupos com padr\u00f5es semelhantes.</p> <p>Coeficiente de Silhouette</p> <p></p> <p>O coeficiente de Silhouette mede, de \u22121 a 1, o qu\u00e3o coesos e separados est\u00e3o os clusters. Valores mais altos indicam melhor separa\u00e7\u00e3o intr\u00ednseca. Usamos este gr\u00e1fico para confirmar a escolha de k observada no cotovelo.</p> <p>visto isso, utilizamos os seguinte clusters:</p> <p>char_freq_! (uso do caractere \"!\")</p> <p>word_freq_free (uso da palavra \"free\")</p> <p>O gr\u00e1fico abaixo mostra os dois clusters encontrados pelo K-Means, com seus respectivos centr\u00f3ides (estrelas vermelhas):</p> <p></p> <p>Emails com maior frequ\u00eancia de \"!\" e \"free\" tendem a ser agrupados no cluster associado a spam. J\u00e1 Emails com baixa frequ\u00eancia desses elementos ficam concentrados no cluster de n\u00e3o-spam.</p>"},{"location":"K-means/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de K-Means aplicado ao dataset Spambase mostrou-se uma ferramenta \u00fatil para a explora\u00e7\u00e3o e identifica\u00e7\u00e3o de padr\u00f5es nos emails. As features, ou seja, as vari\u00e1veis que descrevem cada mensagem, como a frequ\u00eancia da palavra \u201cfree\u201d e o uso do caractere \u201c!\u201d, tiveram papel fundamental na forma\u00e7\u00e3o dos clusters, os grupos criados automaticamente pelo algoritmo. Observou-se que os emails com maior presen\u00e7a desses elementos tendem a ser agrupados em um cluster associado ao spam, enquanto aqueles com baixa frequ\u00eancia permanecem no grupo de n\u00e3o-spam. Embora o K-Means n\u00e3o atinja o mesmo desempenho de modelos supervisionados, como a \u00c1rvore de Decis\u00e3o ou o KNN, ele alcan\u00e7ou uma separa\u00e7\u00e3o satisfat\u00f3ria das classes, evidenciando que as caracter\u00edsticas lingu\u00edsticas e de formata\u00e7\u00e3o s\u00e3o fortes indicadores de spam. Essa abordagem refor\u00e7a o valor do K-Means como t\u00e9cnica explorat\u00f3ria, capaz de revelar padr\u00f5es ocultos nos dados e oferecer uma vis\u00e3o inicial relevante, mesmo sem utilizar a vari\u00e1vel alvo.</p>"},{"location":"KNN/main/","title":"Knn","text":""},{"location":"KNN/main/#exploracao","title":"explora\u00e7\u00e3o","text":"<p>O dataset cont\u00e9m 4601 observa\u00e7\u00f5es, no qual cada linha representa um email, descrito por 58 atributos. Desses, 57 s\u00e3o caracter\u00edsticas extra\u00eddas do texto (frequ\u00eancia de palavras, caracteres especiais, uso de mai\u00fasculas, etc.) e 1 \u00e9 a vari\u00e1vel alvo (is_spam), indicando se o email \u00e9 spam (1) ou n\u00e3o-spam (0).</p> <p>Assim como na etapa da \u00e1rvore de decis\u00e3o, foi realizada uma an\u00e1lise explorat\u00f3ria para compreender melhor o comportamento das classes e identificar os atributos mais relevantes.</p>"},{"location":"KNN/main/#dispersao-por-classe","title":"Dispers\u00e3o por classe","text":"<p>O gr\u00e1fico de dispers\u00e3o foi constru\u00eddo utilizando a frequ\u00eancia do caractere ! e a palavra \u201cfree\u201d, ambos comuns em spams. Percebe-se que os emails classificados como spam (X vermelho) tendem a concentrar maiores valores dessas vari\u00e1veis, enquanto os n\u00e3o-spam (c\u00edrculos azuis) aparecem em menor intensidade.</p> <p></p> <p>Dos 921 emails no conjunto de teste, 836 foram classificados corretamente.</p> <p>A classe N\u00e3o-Spam obteve precis\u00e3o de 92% e recall de 93%.</p> <p>A classe Spam apresentou precis\u00e3o de 89% e recall de 88%, ou seja, teve um pouco mais de dificuldade em identificar spams corretamente, mas ainda com bom desempenho.</p> <p>Esses n\u00fameros indicam que o modelo tem boa capacidade de generaliza\u00e7\u00e3o, conseguindo capturar padr\u00f5es importantes para distinguir spam de n\u00e3o-spam.</p> <p></p> <p>Foi avaliado o impacto da escolha de k no desempenho. Valores muito pequenos de k tendem a causar overfitting (alta variabilidade), enquanto valores muito grandes podem suavizar demais as fronteiras de decis\u00e3o.</p> <p>O melhor equil\u00edbrio foi observado em torno de k=5, valor adotado para os testes principais.</p> <p></p> <p>Esse gr\u00e1fico mostra a proje\u00e7\u00e3o dos dados em duas dimens\u00f5es (PCA 1 e PCA 2) para permitir a visualiza\u00e7\u00e3o da fronteira de decis\u00e3o do KNN. As regi\u00f5es coloridas de fundo indicam onde o modelo classifica como spam ou n\u00e3o-spam, enquanto os pontos representam os exemplos reais do conjunto de treino (roxos) e de teste (amarelos). Observa-se que a maior concentra\u00e7\u00e3o dos pontos est\u00e1 pr\u00f3xima ao centro, regi\u00e3o em que ocorre maior sobreposi\u00e7\u00e3o entre as classes, o que explica parte dos erros de classifica\u00e7\u00e3o. Ainda assim, \u00e9 poss\u00edvel perceber \u00e1reas bem delimitadas, mostrando que o modelo consegue capturar padr\u00f5es \u00fateis mesmo em um espa\u00e7o reduzido para duas dimens\u00f5es. Essa visualiza\u00e7\u00e3o ilustra como o KNN define suas fronteiras a partir da proximidade entre os pontos, destacando tanto a efic\u00e1cia quanto as limita\u00e7\u00f5es do m\u00e9todo em cen\u00e1rios com dados parcialmente sobrepostos.</p>"},{"location":"KNN/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de KNN aplicado ao dataset Spambase apresentou um desempenho consistente, alcan\u00e7ando cerca de 91% de acur\u00e1cia nos dados de teste. Esse resultado demonstra que o algoritmo foi capaz de aprender padr\u00f5es relevantes que diferenciam mensagens leg\u00edtimas de spams, oferecendo uma solu\u00e7\u00e3o simples, por\u00e9m eficiente, para esse tipo de tarefa.</p> <p>Diferentemente da \u00c1rvore de Decis\u00e3o, que gera regras interpret\u00e1veis e permite visualizar a import\u00e2ncia de cada vari\u00e1vel, o KNN se apoia unicamente na proximidade entre exemplos no espa\u00e7o de atributos. Essa caracter\u00edstica faz com que o modelo seja menos transparente em termos de explica\u00e7\u00e3o, mas ao mesmo tempo garante flexibilidade, j\u00e1 que ele pode se adaptar bem a fronteiras de decis\u00e3o complexas.</p> <p>A an\u00e1lise explorat\u00f3ria refor\u00e7ou que atributos como a presen\u00e7a da palavra \u201cfree\u201d, o uso de caracteres especiais como \u201c!\u201d e \u201c$\u201d, al\u00e9m da frequ\u00eancia de letras mai\u00fasculas, est\u00e3o fortemente associados ao spam. Esses sinais refletem pr\u00e1ticas comuns em mensagens indesejadas, como apelos visuais e tentativas de chamar a aten\u00e7\u00e3o do usu\u00e1rio.</p> <p>Apesar da boa performance, algumas limita\u00e7\u00f5es s\u00e3o inerentes ao KNN. O algoritmo demanda maior custo computacional em bases grandes, pois cada nova predi\u00e7\u00e3o exige o c\u00e1lculo da dist\u00e2ncia em rela\u00e7\u00e3o a todos os pontos de treinamento. Al\u00e9m disso, seu desempenho \u00e9 sens\u00edvel \u00e0 escolha do par\u00e2metro k e \u00e0 necessidade de normaliza\u00e7\u00e3o dos dados \u2014 aspectos que, se n\u00e3o tratados corretamente, podem reduzir sua efic\u00e1cia.</p> <p>De forma geral, o KNN mostrou-se uma alternativa vi\u00e1vel e robusta para a classifica\u00e7\u00e3o de spams no dataset Spambase, com a vantagem de ser um m\u00e9todo intuitivo e de f\u00e1cil implementa\u00e7\u00e3o. No entanto, para cen\u00e1rios de produ\u00e7\u00e3o em larga escala, seria interessante compar\u00e1-lo com algoritmos mais escal\u00e1veis e interpret\u00e1veis, de modo a equilibrar desempenho, custo e explicabilidade.</p>"},{"location":"Random-Forest/main/","title":"Modelo de Random Forest","text":""},{"location":"Random-Forest/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Ap\u00f3s a implementa\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o, o pr\u00f3ximo passo foi aplicar o Random Forest, uma t\u00e9cnica de aprendizado supervisionado baseada no princ\u00edpio do ensemble learning. O m\u00e9todo consiste em treinar diversas \u00e1rvores de decis\u00e3o independentes e combinar seus resultados, de modo que o voto majorit\u00e1rio determine a classifica\u00e7\u00e3o final.</p> <p>Essa abordagem reduz o risco de overfitting (quando o modelo \u201cdecorra\u201d os dados de treino) e aumenta a precis\u00e3o geral da previs\u00e3o, tornando o modelo mais robusto e est\u00e1vel.</p>"},{"location":"Random-Forest/main/#implementacao-do-modelo","title":"Implementa\u00e7\u00e3o do Modelo","text":"<p>O modelo foi implementado utilizando apenas a biblioteca scikit-learn, conforme a metodologia adotada em aula.</p> <p>from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import pandas as pd from pathlib import Path import numpy as np</p> <p>--&gt; Carrega o dataset Spambase</p> <p>PATH_DATA = Path(\"source\") df = pd.read_csv(PATH_DATA / \"spambase.csv\", header=None, names=colnames)</p> <p>X = df.drop(columns=[\"is_spam\"]) y = df[\"is_spam\"].astype(int)</p> <p>--&gt; Divide os dados em treino e teste (80/20)</p> <p>X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.2, random_state=42 )</p> <p>--&gt; Cria e treina o modelo Random Forest</p> <p>rf = RandomForestClassifier(     n_estimators=100,     max_depth=5,     max_features='sqrt',     random_state=42 ) rf.fit(X_train, y_train)</p> <p>--&gt; Avalia o modelo</p> <p>pred = rf.predict(X_test) print(f\"Accuracy: {accuracy_score(y_test, pred):.4f}\")</p> <p>--&gt; Mostra as 10 features mais importantes</p> <p>importances = rf.feature_importances_ feat_names = np.array(X.columns) order = np.argsort(importances)[::-1][:10]</p>"},{"location":"Random-Forest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O modelo de Random Forest apresentou um excelente desempenho, alcan\u00e7ando uma acur\u00e1cia de 92,4% nos dados de teste. Esse valor indica que, a cada 100 e-mails analisados, aproximadamente 92 foram classificados corretamente como spam ou n\u00e3o-spam.</p> <p>O resultado demonstra que a combina\u00e7\u00e3o de v\u00e1rias \u00e1rvores aumenta significativamente a capacidade de generaliza\u00e7\u00e3o do modelo, tornando-o mais confi\u00e1vel do que uma \u00fanica \u00e1rvore de decis\u00e3o.</p> <p>Principais Vari\u00e1veis (Import\u00e2ncia das Features)</p> <p>As dez vari\u00e1veis mais relevantes identificadas pelo modelo foram:</p> <p>Ranking Feature Import\u00e2ncia 1   char_freq_$ 0.1329 2   char_freq_! 0.1249 3   word_freq_remove    0.1024 4   word_freq_free  0.0787 5   word_freq_hp    0.0551 6   capital_run_length_average  0.0535 7   word_freq_your  0.0522 8   capital_run_length_longest  0.0505 9   capital_run_length_total    0.0424 10  word_freq_money 0.0366</p> <p>Essas vari\u00e1veis refletem com clareza o comportamento t\u00edpico de e-mails de spam:</p> <p>S\u00edmbolos monet\u00e1rios e de \u00eanfase ($ e !) aparecem em excesso, buscando chamar a aten\u00e7\u00e3o do leitor.</p> <p>Palavras-chave como \u201cfree\u201d, \u201cmoney\u201d e \u201cyour\u201d s\u00e3o amplamente utilizadas para promover ofertas enganosas.</p> <p>Letras mai\u00fasculas e longos blocos de texto em caixa alta (capital_run_length) refor\u00e7am o padr\u00e3o apelativo caracter\u00edstico de mensagens de spam.</p>"},{"location":"Random-Forest/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de Random Forest aplicado ao dataset Spambase apresentou \u00f3tima performance e forte capacidade de generaliza\u00e7\u00e3o, com acur\u00e1cia de 92,4%. A t\u00e9cnica demonstrou-se mais est\u00e1vel e precisa que uma \u00e1rvore de decis\u00e3o isolada, pois reduz o impacto de ru\u00eddos e outliers no conjunto de dados.</p> <p>A an\u00e1lise das vari\u00e1veis mais importantes confirma o comportamento esperado: spams utilizam linguagem apelativa, repetem s\u00edmbolos de \u00eanfase e abusam de termos relacionados a ganhos financeiros.</p> <p>De forma geral, o Random Forest mostrou-se uma ferramenta eficiente e confi\u00e1vel para detec\u00e7\u00e3o autom\u00e1tica de e-mails spam \u2014 equilibrando desempenho, interpretabilidade e robustez.</p>"},{"location":"arvore-decisao/main/","title":"\u00c1rvore de Decis\u00e3o","text":""},{"location":"arvore-decisao/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>Para o projeto foi utilizado o dataset Spambase</p> <p>O dataset utilizado foi o Spambase, Ele cont\u00e9m 4601 observa\u00e7\u00f5es, no qual s\u00e3o emails e apresenta 58 atributos, sendo 57 caracter\u00edsticas para avaliar se o email \u00e9 spam ou n\u00e3o e 1 alvo indicando spam ou n\u00e3o-spam. </p> <p>Para entendermos melhor os dados que estamos manipulando, foi gerado algumas analises baseado nos dados do projeto.</p>"},{"location":"arvore-decisao/main/#distribuicao-da-classe","title":"Distribui\u00e7\u00e3o da Classe","text":"<p>O dataset cont\u00e9m 4601, 2788 emails n\u00e3o-spam e 1813 emails spam. Apesar de n\u00e3o ser perfeitamente balanceado, ainda h\u00e1 uma boa representatividade das duas classes.</p>"},{"location":"arvore-decisao/main/#top-10-palavras-mais-frequentes","title":"Top 10 Palavras mais Frequentes","text":"<p>As palavras mais comuns em emails incluem \u201cyou\u201d, \u201cyour\u201d, \u201cfree\u201d e \u201cour\u201d. Palavras utilizadas com frequencia pelas pessoas e que mostra como spams apelam para comunica\u00e7\u00e3o direta com o usu\u00e1rio e ofertas atrativas.</p> <p>Observa\u00e7\u00e3o: george\", \"hp\", \"hpl\" aparecem bastante porque o dataset Spambase foi coletado a partir de emails internos da Hewlett-Packard (HP) nos anos 90. Ou seja, s\u00e3o termos de contexto espec\u00edfico.</p>"},{"location":"arvore-decisao/main/#caracteres-especiais-por-classe","title":"Caracteres Especiais por Classe","text":"<p>Emails classificados como spam apresentam maior frequ\u00eancia dos caracteres \u201c!\u201d e \u201c$\u201d, usados para chamar aten\u00e7\u00e3o (\u201cOFERTA!!!\u201d, \u201cGANHE $$$\u201d). J\u00e1 os n\u00e3o-spam possuem esses s\u00edmbolos em quantidade bem menor.</p>"},{"location":"arvore-decisao/main/#uso-de-maiusculas","title":"Uso de Mai\u00fasculas","text":"<p>Os spams tendem a utilizar mais letras mai\u00fasculas ao longo do texto, com picos muito acima dos emails normais. Isso reflete a pr\u00e1tica de destacar trechos inteiros com mai\u00fasculas para atrair a aten\u00e7\u00e3o do leitor.</p>"},{"location":"arvore-decisao/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Antes de treinar o modelo, foi realizada uma etapa de pr\u00e9-processamento dos dados. Essa fase \u00e9 fundamental para garantir a qualidade do aprendizado, evitando que inconsist\u00eancias ou ru\u00eddos prejudiquem o desempenho do classificador.</p> <p>Verifica\u00e7\u00e3o de valores nulos Foi utilizado o script exploracao.py para inspecionar o dataset. O teste confirmou que n\u00e3o h\u00e1 valores nulos ou ausentes em nenhuma das 58 colunas, eliminando a necessidade de imputa\u00e7\u00e3o ou exclus\u00e3o de registros.</p> <p>Normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o N\u00e3o foi necess\u00e1rio aplicar normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o das vari\u00e1veis, pois o algoritmo de \u00c1rvore de Decis\u00e3o n\u00e3o depende de escalonamento. Ele realiza divis\u00f5es baseadas em valores de corte (thresholds), o que dispensa ajustes na escala das features.</p> <p>Defini\u00e7\u00e3o das features e do alvo As 57 primeiras colunas foram consideradas como vari\u00e1veis independentes (frequ\u00eancia de palavras, caracteres especiais, uso de mai\u00fasculas, etc.), enquanto a \u00faltima coluna (is_spam) foi definida como vari\u00e1vel alvo, indicando se o email \u00e9 spam (1) ou n\u00e3o-spam (0).</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\nPATH_DATA = Path(\"source\")\nPATH_OUT  = Path(\".\")\nPATH_OUT.mkdir(parents=True, exist_ok=True)\n\n# Tive que fazer isso, porque o arquivo para ler as colunas n\u00e3o estava lendo 58 e apenas 52.\ncolnames = [\n    \"word_freq_make\",\"word_freq_address\",\"word_freq_all\",\"word_freq_3d\",\"word_freq_our\",\n    \"word_freq_over\",\"word_freq_remove\",\"word_freq_internet\",\"word_freq_order\",\"word_freq_mail\",\n    \"word_freq_receive\",\"word_freq_will\",\"word_freq_people\",\"word_freq_report\",\"word_freq_addresses\",\n    \"word_freq_free\",\"word_freq_business\",\"word_freq_email\",\"word_freq_you\",\"word_freq_credit\",\n    \"word_freq_your\",\"word_freq_font\",\"word_freq_000\",\"word_freq_money\",\"word_freq_hp\",\n    \"word_freq_hpl\",\"word_freq_george\",\"word_freq_650\",\"word_freq_lab\",\"word_freq_labs\",\n    \"word_freq_telnet\",\"word_freq_857\",\"word_freq_data\",\"word_freq_415\",\"word_freq_85\",\n    \"word_freq_technology\",\"word_freq_1999\",\"word_freq_parts\",\"word_freq_pm\",\"word_freq_direct\",\n    \"word_freq_cs\",\"word_freq_meeting\",\"word_freq_original\",\"word_freq_project\",\"word_freq_re\",\n    \"word_freq_edu\",\"word_freq_table\",\"word_freq_conference\",\n    \"char_freq_;\",\"char_freq_(\",\"char_freq_[\",\"char_freq_!\",\"char_freq_$\",\"char_freq_#\",\n    \"capital_run_length_average\",\"capital_run_length_longest\",\"capital_run_length_total\",\n    \"is_spam\"\n]\n\n# Ler dados \ndf = pd.read_csv(PATH_DATA / \"spambase.csv\", header=None, names=colnames)\n\n# Separa\u00e7\u00e3o y e X\nX = df.drop(columns=[\"is_spam\"])\ny = df[\"is_spam\"].astype(int)\n\n# Divis\u00e3o treino/teste (80% treino, 20% teste)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Treinamento do modelo e avalia\u00e7\u00e3o\nclassifier = DecisionTreeClassifier(random_state=42)\nclassifier.fit(X_train, y_train)\nprint(f\"Accuracy: {classifier.score(X_test, y_test):.2f}\")\n\n# Visualiza\u00e7\u00e3o da \u00e1rvore de decis\u00e3o\nplt.figure(figsize=(12, 10))\ntree.plot_tree(classifier, max_depth=3, filled=True)\nplt.tight_layout()\nplt.savefig(PATH_OUT / \"tree.png\", dpi=200)\nplt.close()\n</code></pre>"},{"location":"arvore-decisao/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Para avaliar o desempenho do modelo de forma justa, foi necess\u00e1rio dividir o dataset em dois subconjuntos:</p> <p>Treinamento (80%) utilizado para o modelo aprender os padr\u00f5es que diferenciam emails de spam e n\u00e3o-spam. Teste (20%) utilizado apenas ap\u00f3s o treinamento, para verificar a capacidade do modelo de generalizar para dados nunca vistos.</p> <p>A divis\u00e3o foi feita com a fun\u00e7\u00e3o train_test_split da biblioteca scikit-learn, fixando random_state=42 para garantir a reprodutibilidade. Isso significa que, mesmo executando o c\u00f3digo v\u00e1rias vezes, a mesma separa\u00e7\u00e3o entre treino e teste ser\u00e1 obtida.</p> <p>from sklearn.model_selection import train_test_split</p> <p>X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.2, random_state=42 )</p> <p>Esse processo \u00e9 essencial para evitar que o modelo memorize apenas os exemplos dispon\u00edveis (overfitting), garantindo que sua avalia\u00e7\u00e3o reflita sua real capacidade de identificar corretamente novos emails.</p>"},{"location":"arvore-decisao/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>Para a tarefa de classifica\u00e7\u00e3o, foi escolhida a t\u00e9cnica de \u00c1rvore de Decis\u00e3o, implementada atrav\u00e9s da classe DecisionTreeClassifier da biblioteca scikit-learn. Esse algoritmo \u00e9 bastante utilizado em problemas de classifica\u00e7\u00e3o por ser simples, interpret\u00e1vel e permitir visualizar claramente quais vari\u00e1veis tiveram maior import\u00e2ncia na decis\u00e3o final.</p> <p>O modelo foi inicializado com o par\u00e2metro random_state=42, garantindo a reprodutibilidade dos resultados, ou seja, que os mesmos dados de treino e teste levem sempre \u00e0s mesmas divis\u00f5es e ao mesmo desempenho.</p> <p>A etapa de treinamento consistiu em ajustar o modelo (fit) aos dados de treino, fornecendo ao algoritmo 80% das observa\u00e7\u00f5es do dataset. Nesse processo, a \u00e1rvore aprende os padr\u00f5es a partir das vari\u00e1veis independentes e a rela\u00e7\u00e3o delas com a vari\u00e1vel alvo (is_spam).</p> <p>Ao final, a \u00e1rvore de decis\u00e3o foi capaz de gerar uma estrutura hier\u00e1rquica de regras que permitem classificar novos emails como spam ou n\u00e3o-spam.</p>"},{"location":"arvore-decisao/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O modelo atingiu 92% de acur\u00e1cia nos dados de teste.</p> <p>isso quer dizer que, de cada 100 emails, cerca de 92 foram classificados corretamente.</p>"},{"location":"arvore-decisao/main/#conclusao","title":"Conclus\u00e3o","text":""},{"location":"arvore-decisao/main/#visualizacao-da-arvore","title":"Visualiza\u00e7\u00e3o da \u00c1rvore","text":"<p>O modelo de \u00c1rvore de Decis\u00e3o treinado sobre o dataset Spambase apresentou um desempenho consistente, alcan\u00e7ando aproximadamente 92% de acur\u00e1cia nos testes. Esse resultado indica que o algoritmo conseguiu aprender de forma eficaz os padr\u00f5es que diferenciam emails de spam e n\u00e3o-spam.</p> <p>A an\u00e1lise explorat\u00f3ria mostrou que spams costumam utilizar com maior frequ\u00eancia palavras como \u201cyou\u201d e \u201cyour\u201d, empregam intensivamente caracteres especiais como \u201c!\u201d e \u201c$\u201d, e fazem uso exagerado de mai\u00fasculas para chamar a aten\u00e7\u00e3o do leitor. Esses elementos refletem estrat\u00e9gias t\u00edpicas de mensagens indesejadas.</p> <p>Por outro lado, termos como \u201cgeorge\u201d e \u201chp\u201d tamb\u00e9m se destacaram, revelando um vi\u00e9s do dataset, j\u00e1 que ele foi coletado em um contexto corporativo espec\u00edfico (emails da Hewlett-Packard nos anos 90). Isso refor\u00e7a a import\u00e2ncia de avaliar a origem e a atualidade dos dados ao aplicar modelos em cen\u00e1rios reais.</p> <p>De modo geral, a \u00c1rvore de Decis\u00e3o demonstrou ser uma t\u00e9cnica eficaz e interpret\u00e1vel para a tarefa de classifica\u00e7\u00e3o de spam. Mas claro, ainda porderiamos utilizar mais ferramentas para aprimorar a \u00e1rvore.</p>"},{"location":"roteiro4/main/","title":"Roteiro 4","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-10-28T10:57:40.953700 image/svg+xml Matplotlib v3.10.5, https://matplotlib.org/ 2025-10-28T10:57:43.240156 image/svg+xml Matplotlib v3.10.5, https://matplotlib.org/ <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"}]}